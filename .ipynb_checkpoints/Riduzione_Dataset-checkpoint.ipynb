{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaJE0Su5tMoq"
   },
   "source": [
    "## Riduzione del dataset\n",
    "\n",
    "In questo notebook, eseguiremo la riduzione del dataset. L'obbiettivo è quello di diminuire la quantità di audio per label ma mantenendo le caratteristiche di sbilanciamento generali del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installazione e importazione delle librerie necessarie\n",
    "\n",
    "Installiamo e importiamo le librerie che ci torneranno utili per la riduzione del dataset. In questo caso Tensorflow sarà utilizzato per estrarre il dataset dalla directory, mentre le restanti saranno utilizate principalmente per tutto ciò che comprende la riduzione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installiamo la libreria di tensorflow\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estrazione dataset\n",
    "La funzione `audio_dataset_from_directory(directory)` è un modo semplice e veloce ottenere per ottenere informazioni dalle **sottodirectory di un dataset**. Il funzionamento di base è uguale a altre funzioni viste durante il corso, come per esempio `image_dataset_from_directory`. Nel nostro caso il dataset è composto da **30 sottodirectory**, che corrispondono a **30 classi**, che verranno rappresentate come **indice numerico**, e ha una **batch_size di 32**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64721 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "# estraiamo il nostro dataset originale\n",
    "train_ds = tf.keras.utils.audio_dataset_from_directory(directory='../original/train/audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero classi: 30\n",
      "Classi: ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "# stampiamo il numero delle classi e i nomi delle classi del dataset\n",
    "print('Numero classi:', len(train_ds.class_names))\n",
    "print('Classi:',train_ds.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzioni utilizzate\n",
    "Andiamo a creare delle funzioni che ci serviranno per la riduzione del dataset.\n",
    "\n",
    "In questo caso la prima funzione `copy_files` si occupa di creare la directory di destinazione (quindi quella del dataset ridotto) e di copiare i file scelti. La seconda funzione `downsample_class` riduce il dataset, mantenendo in questo caso un quantitativo di audio proporzionato alla quantità iniziale.\n",
    "\n",
    "Inizialmente avevamo lasciato 300 audio per ogni label, ma abbiamo pensato che mantenere una percentuale invece di un numero fisso mantiene le caratteristiche di sbilanciamento del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per copiare i file\n",
    "def copy_files(files, src_dir, dest_dir):\n",
    "    if not os.path.exists(dest_dir): # se la directory di destinazione non esiste allora la creo\n",
    "        os.makedirs(dest_dir)\n",
    "    for file in files: # copio ogni file che mi viene passato nella directory di destinazione, quindi nella directory della classe\n",
    "        shutil.copy(os.path.join(src_dir, file), os.path.join(dest_dir, file))\n",
    "\n",
    "# funzione per diminuire la quantità di audio per label\n",
    "def downsample_class(class_dir, class_name, target_dir, ratio):\n",
    "    files = os.listdir(class_dir) # mi salvo tutti i file della classe in una variabile\n",
    "    num_files_to_keep = int(len(files) * ratio) # calcolo la quantità di file che devo mantenere per la classe in questione\n",
    "    files_to_keep = random.sample(files, num_files_to_keep) # scelgo randomicamente i file da mantenere\n",
    "    \n",
    "    # chiamo la funzione precedentemente dichiarata per copiare i file nella directory\n",
    "    copy_files(files_to_keep, class_dir, os.path.join(target_dir, class_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quindi utilizziamo le funzioni appena dichiarate per ridurre il dataset dell'80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = '../original/train/audio' # path dataset originale\n",
    "downsampled_dir = '../reduced_dataset/train/audio' # path dataset ridotto\n",
    "\n",
    "classes = [dir for dir in os.listdir(original_dir) if os.path.isdir(os.path.join(original_dir, dir))]\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(original_dir, class_name)\n",
    "    downsample_class(class_dir, class_name, downsampled_dir, 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con queste righe di codice abbiamo terminato la riduzione della parte di training del dataset, passando da una **dimensione iniziale di 1.90 GB con 64721 audio totali** a una **dimensione finale di 389 MB con 12933 audio totali**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMnkQpgQIjQSCq/KWijIiaA",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
