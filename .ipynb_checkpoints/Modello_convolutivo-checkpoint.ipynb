{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c7c54c-0a56-4540-88a7-861340b0fc4e",
   "metadata": {},
   "source": [
    "# Modello convolutivo di base\n",
    "In questo notebook costruiamo un **modello convolutivo di base** cos√¨ da poter avere un'idea migliore del task che stiamo approcciando. Utilizzando un modello di base riusciamo a capire soprattutto che prestazioni riusciamo a ottenere senza troppi sforzi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ad9ec-f968-4dee-b7ef-4aba3b74f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d649778a-9379-4ded-8188-65bd7639ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dbe38373-8cc2-4813-a7c9-6bcf77dc499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12933 files belonging to 30 classes.\n",
      "Using 9054 files for training.\n",
      "Using 3879 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, validation_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory='../reduced_dataset/dataset/audio', \n",
    "    validation_split=0.4, \n",
    "    shuffle=True, \n",
    "    subset='both'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60678f4c-ac40-4ffe-8b5c-d0a2b1fc8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform): \n",
    "    spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128) \n",
    "    spectrogram = tf.abs(spectrogram) \n",
    "    \n",
    "    return spectrogram[..., tf.newaxis] \n",
    "\n",
    "# fonte: funzione presa dal seguente link: https://www.geeksforgeeks.org/audio-recognition-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b88665a-9de1-451b-9556-4753b4e90ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze(audio, labels): \n",
    "    audio = tf.squeeze(audio, axis=-1) \n",
    "    return audio, labels \n",
    "  \n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE) \n",
    "validation_ds = validation_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "\n",
    "# fonte: funzione presa dal seguente link: https://www.geeksforgeeks.org/audio-recognition-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "164aa4a3-b1ec-4bc6-9471-a2159ff787de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_dataset(dataset):\n",
    "    dataset = dataset.map(lambda x, y: (get_spectrogram(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# fonte: funzione presa dal seguente link: https://www.geeksforgeeks.org/audio-recognition-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45c0ce-4245-4a1e-abc5-10469e0b6e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
