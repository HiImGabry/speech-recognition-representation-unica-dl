{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaJE0Su5tMoq"
   },
   "source": [
    "# Riduzione del dataset\n",
    "\n",
    "Lo scopo del seguente notebook è ridurre la quantità di audio per etichetta, cercando di mantenendo il più possibile le caratteristiche di sbilanciamento del dataset originale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installazione e importazione delle librerie necessarie\n",
    "\n",
    "Come di consueto, si procede con l'installazione e la sucessiva importazione delle librerie necessarie per questa fase. In questo caso, Tensorflow servirà per l'estrazione del dataset, mentre le restanti saranno utilizate la manipolazione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrazione dataset\n",
    "La funzione `audio_dataset_from_directory(directory)` rappresenta un modo semplice e veloce per ottenere informazioni dalle **sottodirectory di un dataset**. Il suo funzionamento di base è simile ad altre funzioni viste durante il corso, come per esempio `image_dataset_from_directory`. Nel caso specifico, il dataset è costituito da **30 sottodirectory**, ognuna corrispondente a una delle **30 classi** rappresentate come **indici numerici**, con una **batch_size di 32**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64721 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "# estraiamo il nostro dataset originale\n",
    "dataset = tf.keras.utils.audio_dataset_from_directory(directory='../original/train/audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero classi: 30\n",
      "Classi: ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "# stampiamo il numero delle classi e i nomi delle classi del dataset\n",
    "print('Numero classi:', len(dataset.class_names))\n",
    "print('Classi:',dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzioni utilizzate\n",
    "Andiamo a creare le funzioni che ci serviranno per la riduzione del dataset.\n",
    "\n",
    "La prima funzione, denominata `copy_files`, ha il compito di creare la directory di destinazione per il dataset ridotto e copiare i file selezionati. La seconda funzione, chiamata `downsample_class`, riduce il dataset, mantenendo in questo caso una quantità di audio proporzionato alla quantità iniziale.\n",
    "\n",
    "L'idea iniziale era di campionare 300 audio per ogni classe, ma si è giunti alla soluzione di estrarre un campione in modo casuale anziché un numero costante, così da poter preservare lo sbilanciamento del dataset originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per copiare i file\n",
    "def copy_files(files, src_dir, dest_dir):\n",
    "    if not os.path.exists(dest_dir): # se la directory di destinazione non esiste allora la creo\n",
    "        os.makedirs(dest_dir)\n",
    "    for file in files: # copio ogni file che mi viene passato nella directory di destinazione, quindi nella directory della classe\n",
    "        shutil.copy(os.path.join(src_dir, file), os.path.join(dest_dir, file))\n",
    "\n",
    "# funzione per diminuire la quantità di audio per label\n",
    "def downsample_class(class_dir, class_name, target_dir, ratio):\n",
    "    files = os.listdir(class_dir) # mi salvo tutti i file della classe in una variabile\n",
    "    num_files_to_keep = int(len(files) * ratio) # calcolo la quantità di file che devo mantenere per la classe in questione\n",
    "    files_to_keep = random.sample(files, num_files_to_keep) # scelgo randomicamente i file da mantenere\n",
    "    \n",
    "    # chiamo la funzione precedentemente dichiarata per copiare i file nella directory\n",
    "    copy_files(files_to_keep, class_dir, os.path.join(target_dir, class_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizzando le funzioni appena create, otteniamo un dataset che è il 20% delle dimensioni di quello originale, su cui verranno eseguiti i passaggi successivi. Il set si riduce da una **dimensione iniziale di 1.90 GB contenente 64721 audio totali** a una **dimensione finale di 389 MB con un totale 12933 audio totali**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = '../original/train/audio' # path dataset originale\n",
    "downsampled_dir = '../reduced_dataset/dataset/audio' # path dataset ridotto\n",
    "\n",
    "classes = [dir for dir in os.listdir(original_dir) if os.path.isdir(os.path.join(original_dir, dir))]\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(original_dir, class_name)\n",
    "    downsample_class(class_dir, class_name, downsampled_dir, 0.20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMnkQpgQIjQSCq/KWijIiaA",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
