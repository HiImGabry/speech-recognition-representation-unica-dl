{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b61ba5b-7aa7-4750-b9fe-be77ce4503c3",
   "metadata": {},
   "source": [
    "# Indice dei Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a16d7-c333-4b27-a31c-931fff3f0b55",
   "metadata": {},
   "source": [
    "Lo scopo di questo progetto è creare dei modelli di Reti Neurali che siano in grado di riconoscere comandi vocali. Per fare questo abbiamo scelto di utilizzare il dataset pubblico [TensorFlow Speech Recognition Challenge](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/code?competitionId=7634&sortBy=voteCount&excludeNonAccessedDatasources=true) di Google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32630d2a-3133-4026-b50f-f4db9361cd85",
   "metadata": {},
   "source": [
    "## Analisi dei Dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4ad5d-861f-42ff-8c78-e35f97c37114",
   "metadata": {},
   "source": [
    "Il dataset disponibile era di dimensioni eccessive per il nostro progetto, quindi abbiamo deciso di iniziare [riducendo il dataset](1A_reduce_dataset.ipynb). \n",
    "\n",
    "Successivamente siamo passati una fase di [analisi esplorativa](1B_analisi_dati.ipynb). Questo ci ha permesso di capire quali tipi di dati fossero presenti nel dataset e iniziare a pensare delle possibili soluzioni alla challenge proposta. Fatto ciò, ci siamo posti il problema di rappresentare al meglio i dati a disposizione, cosi da poterli analizzare più profondamente. Le soluzioni trovate sono state la visualizzazione di:\n",
    "- [spettrogrammi](1C_make_spectrogram.ipynb)\n",
    "- [segnali degli audio](1D_make_wave_audio.ipynb) \n",
    "- [filter banks](1E_make_filterbanks.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9c2e1-fe4c-4743-ac18-ab1c4f5c8deb",
   "metadata": {},
   "source": [
    "## Modelli\n",
    "\n",
    "Esplorati i dati ed eseguiti i pre-processamenti necessari, siamo passati alla creazione dei modelli."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93176b6f-2541-41ce-992f-db07de95dd4d",
   "metadata": {},
   "source": [
    "### Convolutivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281e9c2-e4bc-4435-880a-8074293dadb9",
   "metadata": {},
   "source": [
    "Considerando la conversione degli audio in spettrogrammi durante le fasi precedenti, il primo su cui ci siamo concentrati è stato un [modello convolutivo base](2A_conv_base.ipynb), con ottimizzatore RMSProp. Abbiamo eseguito alcuni esperimenti prima di riuscire a trovare un'architettura in grado di eseguire il compito di classificazione dei comandi, taluni più efficaci di altri. Tra questi, abbiamo sostituito l'ottimizzatore con uno [adam](2B_conv_base_adam.ipynb).\n",
    "\n",
    "Siamo passati da un modello che presentava un adattamento eccessivo dopo poche epoche a un modello robusto, in grado di generalizzare e con un'accuratezza notevole. \n",
    "\n",
    "Gli stessi modelli sono stati nuovamente addestrati e valutati con input differenti, come i [filterbank e gli MFCC](2C_training_on_filterbanks.ipynb). Anche in questo caso è stato applicato lo stesso esperimento riguardante la sostituzione dell'ottimizzatore con uno [adam](2D_training_on_filterbanks_adam.ipynb).\n",
    "\n",
    "Terminato ciò abbiamo riprodotto un [modello convolutivo complesso](2E_conv_advanced.ipynb) con architettura VggVox.\n",
    "\n",
    "Quest'ultimo notebook pone fine alla seconda fase del nostro progetto, aprendo le porte al prossimo argomento chiave: la [data augmentation](3A_data_augmentation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f909e99d-3bdc-43cc-b1e3-dea6f0588374",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55eaa3-5517-43da-8222-39889ebeb9a4",
   "metadata": {},
   "source": [
    "Questo argomento ci permette di far risaltare il nostro operato, offrendoci nuove combinazioni di addestramento e valutazione. Abbiamo ripetuto lo stesso procedimento del paragrafo precedente ma utilizzando i concetti appresi e introdotti dal nuovo.\n",
    "\n",
    "Abbiamo quindi addestrato e valutato i modelli utilizzando un dataset modificato con le tecniche trattate nel notebook precedente. In particolare, abbiamo addestrato nuovamente il [modello convolutivo base](3B_conv_base.ipynb), la sua variante con l'ottimizzatore [adam](3C_conv_base_adam.ipynb), e il [modello convolutivo complesso](3D_conv_advanced.ipynb) con architettura VggVox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed0bcb-6820-4efa-9edd-330e56d4703c",
   "metadata": {},
   "source": [
    "## Valutazione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76c6ed-6172-42ec-9a3e-2e04e34bb0f4",
   "metadata": {},
   "source": [
    "Questi esperimenti ci hanno permesso di ottenere un grande quantitativo di modelli addestrati, per un totale di cinquantaquattro (54). Tutte queste informazioni, e tutti questi dati, sono stati [visualizzati, analizzati, e valutati](4A_valutazione.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
