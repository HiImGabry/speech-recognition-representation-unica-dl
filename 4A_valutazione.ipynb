{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "751b9f51-b2f9-4758-be26-88a70f1e6d04",
   "metadata": {},
   "source": [
    "# Valutazioni finali\n",
    "Con questo notebook si conclude il nostro progetto. Trarremo delle considerazione sui risultati ottenuti, approffonendo quali strategia hanno funzionato meglio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec90971-0beb-4b24-9218-e6f8ffa5c1f4",
   "metadata": {},
   "source": [
    "## Funzioni note\n",
    "Le seguenti celle contengono le librerie e le funzioni create durante lo sviluppo del progetto. Non sono state apportate sostanziali modifiche, a ragion di ciò non ne andremo a descrivere nuovamente il funzionamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52578c8a-1c8c-45fb-a305-0d85a20ad359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import scipy.fftpack as scipy\n",
    "import onnxruntime as rt\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b8aee5-bb5d-498f-a194-3991a98d6758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12933 files belonging to 30 classes.\n",
      "Using 7760 files for training.\n",
      "Using 5173 files for validation.\n",
      "Found 14 files belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds, validation_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory='../reduced_dataset/dataset/audio',\n",
    "    validation_split=0.4, # stiamo mettendo da parte il 40% del dataset, che sarà suddiviso in validation set e test set\n",
    "    shuffle=True,\n",
    "    subset='both', # necessario se stiamo utilizzando validation_split (se no darebbe errore)\n",
    "    seed=0 # necessario se stiamo utilizzando sia shuffle che validation_split (se no darebbe errore)\n",
    ")\n",
    "\n",
    "noise_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory='../noise_dataset',\n",
    "    batch_size = 1\n",
    ")\n",
    "\n",
    "noise_label_names = noise_ds.class_names\n",
    "\n",
    "val_ds = validation_ds.take(validation_ds.cardinality() // 2) # ho cambiato nome del validation_ds in modo tale da non creare problemi con l'istruzione seguente\n",
    "test_ds = validation_ds.skip(validation_ds.cardinality() // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f74db1ce-764e-44c8-9569-af740a4bf2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_audios(dataset, length):\n",
    "    new_audios = [] # inizializziamo una lista dove inseriremo i nostri audio tagliati\n",
    "    labels = []\n",
    "    \n",
    "    # iteriamo nel dataset\n",
    "    for audio, label in dataset:\n",
    "        # tagliamo l'audio ad un secondo e lo appendiamo a una lista \n",
    "        labels.append(label.numpy())\n",
    "        \n",
    "        audio = tf.reshape(audio, [-1])[np.shape(audio)[1]//2:np.shape(audio)[1]//2 + length]\n",
    "        new_audios.append(audio.numpy()) # convertiamo in array per poterli modificare\n",
    "        \n",
    "    return new_audios, labels\n",
    "\n",
    "cut_noise_audios, cut_noise_labels = cut_audios(noise_ds, 16000)\n",
    "\n",
    "def mix_audios(original_audios, noise_audios):\n",
    "    mixed_dataset = [] # inizializziamo la lista dove inseriremo gli audio uniti al rumore\n",
    "\n",
    "    original_audios = original_audios.unbatch() # il nostro training set ha una batch_size di 32, per rendere il processo più semplice unbatchiamo\n",
    "    \n",
    "    # per ogni audio del dataset originale\n",
    "    for audio, label in original_audios:    \n",
    "        audio = np.squeeze(audio, axis=-1) # rimuoviamo l'ultima asse inutile (quella dei canali)\n",
    "        \n",
    "        # Scegliamo in modo randomico un audio dalla lista degli audio rumorosi\n",
    "        noise_sample = random.choice(noise_audios)\n",
    "\n",
    "        # calcolo l'ampiezza massima dell'audio rumoroso\n",
    "        max_amplitude_audio = np.max(np.abs(audio))\n",
    "        max_amplitude_noise = np.max(np.abs(noise_sample))\n",
    "        # calcolo un noise factor che varia a seconda dell'ampiezza massima di entrambi gli audio\n",
    "        noise_factor = max_amplitude_audio / max_amplitude_noise\n",
    "        noise_factor = min(noise_factor, 1.0)\n",
    "        \n",
    "        noise_sample = noise_sample * noise_factor\n",
    "        \n",
    "        mixed_audio = audio + noise_sample # uniamo l'audio original al rumore\n",
    "\n",
    "        # aggiungiamo l'audio con noise alla lista\n",
    "        mixed_dataset.append((mixed_audio, label))\n",
    "\n",
    "    return mixed_dataset\n",
    "\n",
    "mixed_train_list = mix_audios(train_ds, cut_noise_audios)\n",
    "mixed_val_list = mix_audios(validation_ds, cut_noise_audios)\n",
    "\n",
    "def create_mixed_ds(dataset_list):\n",
    "    audio_data = [tf.convert_to_tensor(audio, dtype=tf.float32) for audio, label in dataset_list]\n",
    "    labels = [label for _, label in dataset_list]\n",
    "\n",
    "    audio_data = tf.expand_dims(audio_data, axis=-1)\n",
    "    \n",
    "    mixed_train_ds = tf.data.Dataset.from_tensor_slices((audio_data, labels))\n",
    "    mixed_train_ds = mixed_train_ds.batch(32)\n",
    "    return mixed_train_ds\n",
    "\n",
    "mixed_train_ds = create_mixed_ds(mixed_train_list)\n",
    "mixed_validation_ds = create_mixed_ds(mixed_val_list)\n",
    "\n",
    "mixed_val_ds = mixed_validation_ds.take(mixed_validation_ds.cardinality() // 2) # ho cambiato nome del validation_ds in modo tale da non creare problemi con l'istruzione seguente\n",
    "mixed_test_ds = mixed_validation_ds.skip(mixed_validation_ds.cardinality() // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474c96ec-5ad3-4b9b-8acb-fd9c7364f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConverter:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def convert(self, option):\n",
    "        available_options = ['spectrogram', 'filterbanks', 'mfcc']\n",
    "        \n",
    "        if option == available_options[0]:\n",
    "            return self.get_spectrogram_dataset()\n",
    "        elif option == available_options[1]:\n",
    "            return self.get_filterbanks_dataset()\n",
    "        elif option == available_options[2]:\n",
    "            return self.get_mfcc_dataset()\n",
    "        else:\n",
    "            raise ValueError(f\"Opzione non disponibile: inserire una delle seguenti opzioni: {available_options}\")\n",
    "    \n",
    "    # INIZIO SPETTROGRAMMI\n",
    "    def squeeze(self, audio, labels):\n",
    "        audio = tf.squeeze(audio, axis=-1)\n",
    "        return audio, labels\n",
    "    \n",
    "    def get_spectrogram(self, waveform):\n",
    "    # applichiamo la short-time Fourier transorm\n",
    "        spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
    "        spectrogram = tf.abs(spectrogram)\n",
    "        \n",
    "        return spectrogram[..., tf.newaxis]\n",
    "    \n",
    "    def get_spectrogram_dataset(self):\n",
    "        # squeeze\n",
    "        self.dataset = self.dataset.map(self.squeeze, tf.data.AUTOTUNE)\n",
    "        self.dataset = self.dataset.map(lambda x, y: (self.get_spectrogram(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        \n",
    "        return self.dataset\n",
    "\n",
    "    # FINE SPETTROGRAMMI\n",
    "\n",
    "    def convert_to_numpy(self, dataset):\n",
    "        audio_data = []\n",
    "        labels = []\n",
    "    \n",
    "        dataset = dataset.unbatch()\n",
    "        \n",
    "        for audio, label in dataset:\n",
    "            audio_data.append(audio.numpy())  # Assuming audio is a tensor, convert to numpy array\n",
    "            labels.append(label.numpy())      # Assuming label is a tensor, convert to numpy array\n",
    "        \n",
    "        audio_data = np.array(audio_data)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        return audio_data, labels\n",
    "    \n",
    "    # INIZIO FILTERBANKS\n",
    "    def makeHamming(self, M):\n",
    "        R = (( M - 1 ) / 2 , M / 2)[M % 2 == 0]\n",
    "        w = (np.hamming(M), np.hamming(M + 1))[M % 2 == 0]\n",
    "        if M % 2 != 0:\n",
    "            w[0] = w[0]/2\n",
    "            w[M-1] = w[M-1]/2\n",
    "        else:\n",
    "            w = w[:M]\n",
    "    \n",
    "        return w\n",
    "\n",
    "    def hztomel(self, hz):\n",
    "        return (2595 * np.log10(1 + hz / 700))\n",
    "\n",
    "    def meltohz(self, mel):\n",
    "        return (700 * (10**(mel / 2595) - 1))\n",
    "\n",
    "    def compute_filterbanks(self, audios_np, pre_emphasis=0.97, sample_rate=16000, frame_size=0.025, frame_stride=0.01, NFFT=512, nfilt=40):\n",
    "        filterbanks_np = []\n",
    "        \n",
    "        for samples in audios_np:\n",
    "            emphasized_audio = np.append(samples[0], samples[1:] - pre_emphasis * samples[:-1])\n",
    "            audio_length = len(emphasized_audio)\n",
    "    \n",
    "            frame_length, frame_step = int(frame_size * sample_rate), int(frame_stride * sample_rate)\n",
    "    \n",
    "            num_frames = int(np.ceil(float(np.abs(audio_length - frame_length)) / frame_step))\n",
    "    \n",
    "            pad_audio_length = num_frames * frame_step + frame_length\n",
    "            z = np.zeros((pad_audio_length - audio_length))\n",
    "            pad_audio = np.append(emphasized_audio, z)\n",
    "    \n",
    "            indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "            frames = pad_audio[indices.astype(np.int32, copy=False)]\n",
    "    \n",
    "            # Usiamo la funzione di Hamming\n",
    "            hamming_window = self.makeHamming(frame_length)\n",
    "    \n",
    "            mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitudo della FFT\n",
    "            pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))\n",
    "    \n",
    "            # convertiamo hz in mel\n",
    "            low_freq_mel = self.hztomel(0)\n",
    "            high_freq_mel = self.hztomel(sample_rate / 2)\n",
    "    \n",
    "            mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)\n",
    "            hz_points = self.meltohz(mel_points) \n",
    "    \n",
    "            bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
    "    \n",
    "            fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
    "    \n",
    "            for m in range(1, nfilt + 1):\n",
    "                f_m_minus = int(bin[m - 1])\n",
    "                f_m = int(bin[m])\n",
    "                f_m_plus = int(bin[m + 1])\n",
    "    \n",
    "                for k in range(f_m_minus, f_m):\n",
    "                    fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "                for k in range(f_m, f_m_plus):\n",
    "                    fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    \n",
    "            # in questo momento invece calcoliamo i filter banks per i segmenti di audio, utilizzando i filtri triangolari appena creati\n",
    "            filter_banks = np.dot(pow_frames, fbank.T)\n",
    "            filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)\n",
    "            filter_banks = 20 * np.log10(filter_banks)\n",
    "    \n",
    "            filterbanks_np.append(filter_banks)\n",
    "        \n",
    "        return np.array(filterbanks_np)\n",
    "    \n",
    "    def get_filterbanks_dataset(self): \n",
    "        audios, labels = self.convert_to_numpy(self.dataset)\n",
    "\n",
    "        filterbanks = self.compute_filterbanks(audios)\n",
    "        filterbanks = np.expand_dims(filterbanks, axis=-1)\n",
    "\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((filterbanks, labels))\n",
    "        self.dataset = self.dataset.batch(32)\n",
    "        \n",
    "        return self.dataset\n",
    "    # FINE FILTERBANKS\n",
    "\n",
    "    # INIZIO MFCC\n",
    "    def compute_mfcc(self, filter_banks, num_ceps=12, cep_lifter=22):\n",
    "        mfcc_np = []\n",
    "        \n",
    "        for f in filter_banks:\n",
    "            mfcc = scipy.dct(f, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)]\n",
    "\n",
    "            (nframes, ncoeff) = mfcc.shape\n",
    "            n = np.arange(ncoeff)\n",
    "            \n",
    "            lift = 1 + (cep_lifter / 2) * np.sin(np.pi * n / cep_lifter)\n",
    "            mfcc *= lift\n",
    "\n",
    "            mfcc_np.append(mfcc)\n",
    "        \n",
    "        return np.array(mfcc_np)\n",
    "    \n",
    "    \n",
    "    def get_mfcc_dataset(self):\n",
    "        audios, labels = self.convert_to_numpy(self.dataset)\n",
    "\n",
    "        filterbanks = self.compute_filterbanks(audios)\n",
    "        mfcc = self.compute_mfcc(filterbanks)\n",
    "        \n",
    "        mfcc = np.expand_dims(mfcc, axis=-1)\n",
    "        \n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((mfcc, labels))\n",
    "        self.dataset = self.dataset.batch(32)\n",
    "        \n",
    "        return self.dataset\n",
    "    \n",
    "    # FINE MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffab4c-9bd6-4c6d-8ee0-7913935fa0de",
   "metadata": {},
   "source": [
    "## Funzioni nuove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3688fc0-f4bb-4c4a-98b2-ffb676d2d96e",
   "metadata": {},
   "source": [
    "Per poter rappresentare i dati ottenuti abbiamo dovuto modificare `evaluate_onnx_model`. Se fino ad ora questa funzione aveva solamente la funzione di printare le metriche di valutazioni migliori, ora restituisce direttamente l'accuratezza e la perdita. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46883168-0326-45c5-a6c9-f2f7f8018707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_onnx_model(path_model_onnx, test_ds):\n",
    "    # il fatto che sia suddiviso in batch mi crea problemi, perciò lo risolvo togliendoli\n",
    "    test_ds = test_ds.unbatch()\n",
    "    \n",
    "    # carico il modello utilizzando il file onnx\n",
    "    m = rt.InferenceSession(path_model_onnx)\n",
    "    \n",
    "    # trasformo il dataset in array numpy\n",
    "    spectrogram_np = np.array([spectrogram.numpy() for spectrogram, _ in test_ds], dtype=np.float32)\n",
    "    labels_np = np.array([label.numpy() for _, label in test_ds])\n",
    "    \n",
    "    # eseguo le predizione del modello\n",
    "    pred_onnx = m.run(None, {'input': spectrogram_np})\n",
    "    # ottengo la predizione corretta\n",
    "    predictions = np.argmax(pred_onnx[0], axis=1)\n",
    "    # computo la accuratezza\n",
    "    accuracy = np.mean(predictions == labels_np)\n",
    "    # computo la loss\n",
    "    sparse_categorical_loss = tf.keras.losses.sparse_categorical_crossentropy(labels_np, pred_onnx[0])\n",
    "    mean_sparse_categorical_loss = np.mean(sparse_categorical_loss)\n",
    "    # stampo l'accuratezza\n",
    "    return round(accuracy, 3), round(mean_sparse_categorical_loss, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78cbc4-4169-4ec5-b787-81f0c08599c2",
   "metadata": {},
   "source": [
    "Per poter analizzare meglio le reti create è stata sviluppata la funzione `create_table`, la quale crea una struttura DataFrame di Pandas in base al dataset e all'ottimizzatore passati come argomenti e alla scelta di avere o meno il dataset rumoroso. Imposta di default come ottimizzatore **rmsprop** e sceglie il dataset senza rumore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e06cebbe-20c1-4a68-aa9b-bbf2dfedd9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creiamo le colonne e il dataframe\n",
    "headers = [\"Modello\", \"Opt\", \"Dataset\", \"Rumore\", \"Accuratezza\", \"Perdita\"]\n",
    "\n",
    "def create_table(dataset_name, optimizer=\"rmsprop\", noise=False):\n",
    "    if noise:\n",
    "        dataset = DatasetConverter(mixed_test_ds)\n",
    "        dataset = dataset.convert(dataset_name)\n",
    "    else:\n",
    "        dataset = DatasetConverter(test_ds)\n",
    "        dataset = dataset.convert(dataset_name)\n",
    "        \n",
    "    path = f\"bestmodels/noise/{optimizer}/\" if noise else f\"bestmodels/{optimizer}/\"\n",
    "    path += dataset_name + \"/\"\n",
    "\n",
    "    df = pd.DataFrame(columns=headers)\n",
    "\n",
    "    for model in os.listdir(path):\n",
    "        if model.endswith(\"onnx\"):\n",
    "            new_row = []\n",
    "            model_name = model.split(\".onnx\")[0]\n",
    "            model_name = model_name.split(\"_\")\n",
    "            \n",
    "            if model_name[-1] != \"model\":\n",
    "                model_name = model_name[:-1]\n",
    "\n",
    "            model_name = \"_\".join(model_name)\n",
    "  \n",
    "            new_row.append(model_name)\n",
    "\n",
    "            new_row.append(optimizer)\n",
    "            \n",
    "            new_row.append(path.split(\"/\")[-2])\n",
    "            \n",
    "            if noise:\n",
    "                new_row.append(\"Sì\")\n",
    "            else:\n",
    "                new_row.append(\"No\")\n",
    "\n",
    "            accuracy, loss = evaluate_onnx_model(path+model, dataset)\n",
    "            new_row.append(accuracy)\n",
    "            new_row.append(loss)\n",
    "\n",
    "            df.loc[-1] = new_row\n",
    "            df.index = df.index + 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c25c7a-81d9-4740-86ea-ff2bcbc3a625",
   "metadata": {},
   "source": [
    "## Dataset originale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915040ff-e762-4e42-8c76-a4431c6a7e4d",
   "metadata": {},
   "source": [
    "### Valutazione spettrogrammi\n",
    "Partiamo da analizzare i risultati dei modelli con il primo tipo di dati creati a partire dal nostro dataset di audio di partenza. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3650f-fa6f-4b14-b94e-9140c9fccac8",
   "metadata": {},
   "source": [
    "Per farlo abbiamo bisogno di creare due dataframe, uno per l'ottimizzatore rmsprop e un altro per l'adam, che uniremo per creare una tabella unica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033aab1f-899b-4e4e-8eb7-c5a1a1b80e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Opt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rumore</th>\n",
       "      <th>Accuratezza</th>\n",
       "      <th>Perdita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voxprofunda</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.775</td>\n",
       "      <td>1.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.769</td>\n",
       "      <td>1.145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modello      Opt      Dataset Rumore  Accuratezza  \\\n",
       "0                 voxprofunda     adam  spectrogram     No        0.932   \n",
       "1              bp_basic_model     adam  spectrogram     No        0.897   \n",
       "2              bp_basic_model  rmsprop  spectrogram     No        0.891   \n",
       "3        improved_basic_model  rmsprop  spectrogram     No        0.863   \n",
       "4        improved_basic_model     adam  spectrogram     No        0.855   \n",
       "5                 basic_model  rmsprop  spectrogram     No        0.828   \n",
       "6                 basic_model     adam  spectrogram     No        0.788   \n",
       "7  tuned_improved_basic_model  rmsprop  spectrogram     No        0.775   \n",
       "8  tuned_improved_basic_model     adam  spectrogram     No        0.769   \n",
       "\n",
       "   Perdita  \n",
       "0    0.326  \n",
       "1    0.448  \n",
       "2    0.437  \n",
       "3    0.549  \n",
       "4    0.649  \n",
       "5    0.804  \n",
       "6    0.788  \n",
       "7    1.066  \n",
       "8    1.145  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spect_rmsprop = create_table(\"spectrogram\")\n",
    "df_spect_adam = create_table(\"spectrogram\", optimizer=\"adam\")\n",
    "\n",
    "# Aggiunta resnet\n",
    "spect_test_ds = DatasetConverter(test_ds)\n",
    "spect_test_ds = spect_test_ds.convert(\"spectrogram\")\n",
    "\n",
    "acc, loss = evaluate_onnx_model(\"bestmodels/resnet/voxprofunda_spect.onnx\", spect_test_ds)\n",
    "new_row = [\"voxprofunda\", \"adam\", \"spectrogram\", \"No\", acc, loss]\n",
    "\n",
    "df_spect_adam.loc[-1] = new_row; df_spect_adam.index = df_spect_adam.index + 1\n",
    "# fine aggiunta resnet\n",
    "\n",
    "df_spect = pd.concat([df_spect_rmsprop, df_spect_adam]).sort_values(by=\"Accuratezza\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_spect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d6499-87c0-4efd-b742-bd81d0cf40af",
   "metadata": {},
   "source": [
    "Da questa tabella possiamo notare come le differenze tra i due ottimizzatori non siano marcate, ma in quasi tutti i casi **rmsprop** per questo tipo di dati ha performato meglio. \n",
    "\n",
    "Esaminando nello specifico i singoli modelli si può osservare come la rete convolutivo base partisse con un buon valore di accuratezza, intorno all'**80%**, ma aggiungendo un semplice livello di dropout questa metrica si è attesta sull'**85%**.\n",
    "\n",
    "I risultati migliori sono stati ottenuti dall'adozione delle best practice. L'impiego di blocchi residui ha fatto sì che il modello raggiungesse un risultato di quasi **90%** di accuratezza, ben **10** punti percentuali in più rispetto al primo convolutivo.\n",
    "\n",
    "Come ci aspettavamo, l'architettura VGGVox è quella che ha portato risultati migliori, superando il **93%**. Detto ciò bisogna considerare anche il numero elevato di parametri, circa **23.5M**, mentre la rete convolutiva con i blocchi residui ne ha poco più del **0.7%**. \n",
    "\n",
    "Scarsi i risultati ottenuti dalla tecnica di tuning degli iperparametri, dove si è raggiunta l'accuratezza più bassa tra tutti i modelli. Questo probabilmente dovuto al fatto che è stato impiegato un tasso di apprendimento fisso, mentre per gli altri modelli sono stati usati dei tassi di apprendimento dinamici, i quali si adattano ad ogni epoca. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba6ef7-3422-4c30-90b0-c9939f0ac36d",
   "metadata": {},
   "source": [
    "## Valutazione filterbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5277b79a-2f96-4d76-8cad-a842fe8333a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Opt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rumore</th>\n",
       "      <th>Accuratezza</th>\n",
       "      <th>Perdita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voxprofunda</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>No</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>No</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>No</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>No</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>No</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>No</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>No</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>No</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>No</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modello      Opt      Dataset Rumore  Accuratezza  \\\n",
       "0                 voxprofunda     adam  filterbanks     No        0.917   \n",
       "1        improved_basic_model  rmsprop  filterbanks     No        0.881   \n",
       "2              bp_basic_model     adam  filterbanks     No        0.881   \n",
       "3              bp_basic_model  rmsprop  filterbanks     No        0.871   \n",
       "4  tuned_improved_basic_model     adam  filterbanks     No        0.848   \n",
       "5  tuned_improved_basic_model  rmsprop  filterbanks     No        0.846   \n",
       "6        improved_basic_model     adam  filterbanks     No        0.843   \n",
       "7                 basic_model     adam  filterbanks     No        0.831   \n",
       "8                 basic_model  rmsprop  filterbanks     No        0.824   \n",
       "\n",
       "   Perdita  \n",
       "0    0.346  \n",
       "1    0.532  \n",
       "2    0.531  \n",
       "3    0.607  \n",
       "4    0.598  \n",
       "5    0.601  \n",
       "6    0.579  \n",
       "7    0.617  \n",
       "8    0.659  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fb_rmsprop = create_table(\"filterbanks\")\n",
    "df_fb_adam = create_table(\"filterbanks\", optimizer=\"adam\")\n",
    "\n",
    "# Aggiunta resnet\n",
    "fb_test_ds = DatasetConverter(test_ds)\n",
    "fb_test_ds = fb_test_ds.convert(\"filterbanks\")\n",
    "\n",
    "acc, loss = evaluate_onnx_model(\"bestmodels/resnet/voxprofunda_fb.onnx\", fb_test_ds)\n",
    "new_row = [\"voxprofunda\", \"adam\", \"filterbanks\", \"No\", acc, loss]\n",
    "\n",
    "df_fb_adam.loc[-1] = new_row; df_fb_adam.index = df_fb_adam.index + 1\n",
    "# fine aggiunta resnet\n",
    "\n",
    "df_fb = pd.concat([df_fb_rmsprop, df_fb_adam]).sort_values(by=\"Accuratezza\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_fb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174fb3c-1a5e-4547-8aed-1c54ad42100d",
   "metadata": {},
   "source": [
    "Sfruttando i filterbank i modelli più semplici hanno performato meglio rispetto agli spettrogrammi e le differenze tra gli ottimizzatori sono più rilevanti. In linea generale per questo tipo di dati quello ad avere la meglio è stato l'**adam**. \n",
    "\n",
    "Il modello convolutivo di partenza ha performato in modo smile a quello usato per gli spettrogrammi, infatti raggiunge un'accuratezza dell'**82%** con ottimizzare **rmsprop**. Interessante notare come dopo aver aggiunto lo strato di dropout la rete ottiene un miglioramento notevole con **88%**, ma lo stesso risultato non avviene per l'ottimizzatore **adam**, il quale migliora di appena **1** punto percentuale.  \n",
    "\n",
    "I modelli a cui è stato effettuato il tuning degli iperparametri questa volta hanno apportato dei miglioramenti rispetto all'architettura base, anche se solo di qualche punto percentile.\n",
    "\n",
    "Anche in questo specifico caso i modelli a cui sono state effettuate le best practice hanno ottenuto i benefici migliori salendo a **88%** e **87%** di accuracy, rispettivamente per **adam** e **rmsprop**. \n",
    "\n",
    "L'archiettura VGGVox ha performato meglio di tutte, ma peggio rispetto alla corrispettiva impiegata con il dataset di spettrogrammi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7cb08b-b5b3-47db-8f2d-2b92498f585a",
   "metadata": {},
   "source": [
    "## Valutazione MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99089ad0-28ba-4d44-9b17-e93ac5f2d383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Opt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rumore</th>\n",
       "      <th>Accuratezza</th>\n",
       "      <th>Perdita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voxprofunda</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.683</td>\n",
       "      <td>1.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.681</td>\n",
       "      <td>1.147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modello      Opt Dataset Rumore  Accuratezza  Perdita\n",
       "0                 voxprofunda     adam    mfcc     No        0.882    0.400\n",
       "1              bp_basic_model     adam    mfcc     No        0.831    0.740\n",
       "2        improved_basic_model  rmsprop    mfcc     No        0.814    0.786\n",
       "3                 basic_model  rmsprop    mfcc     No        0.797    0.850\n",
       "4              bp_basic_model  rmsprop    mfcc     No        0.796    0.795\n",
       "5        improved_basic_model     adam    mfcc     No        0.780    0.875\n",
       "6                 basic_model     adam    mfcc     No        0.742    0.968\n",
       "7  tuned_improved_basic_model     adam    mfcc     No        0.683    1.146\n",
       "8  tuned_improved_basic_model  rmsprop    mfcc     No        0.681    1.147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc_rmsprop = create_table(\"mfcc\")\n",
    "df_mfcc_adam = create_table(\"mfcc\", optimizer=\"adam\")\n",
    "\n",
    "# Aggiunta resnet\n",
    "mfcc_test_ds = DatasetConverter(test_ds)\n",
    "mfcc_test_ds = mfcc_test_ds.convert(\"mfcc\")\n",
    "\n",
    "acc, loss = evaluate_onnx_model(\"bestmodels/resnet/voxprofunda_mfcc.onnx\", mfcc_test_ds)\n",
    "new_row = [\"voxprofunda\", \"adam\", \"mfcc\", \"No\", acc, loss]\n",
    "\n",
    "df_mfcc_adam.loc[-1] = new_row; df_mfcc_adam.index = df_mfcc_adam.index + 1\n",
    "# fine aggiunta resnet\n",
    "\n",
    "df_mfcc = pd.concat([df_mfcc_rmsprop, df_mfcc_adam]).sort_values(by=\"Accuratezza\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cfc943-2234-4c61-b8ed-b26086668341",
   "metadata": {},
   "source": [
    "I tipi di dati MFCC sono stati quelli che hanno messo più in difficoltà i modelli. Quelli a cui è stato impostato come ottimizzatore rmsprop hanno performato meglio. \n",
    "\n",
    "La rete di partenza con l'ottimizzatore migliore ha raggiunto performance simili a quelle della stessa allenata con gli altri tipi di dati e le migliorie apportate non hanno condotto a risultati significativi, andando anche a peggiorare con l'impiego dei blocchi residui. \n",
    "\n",
    "La stessa rete in cui è stato impostato l'ottimizzatore peggiore ha seguito un andamento simile ribasatto di qualche punto, eccezion fatta per quella che impiega le best practice che è riuscita a performare meglio di tutte. \n",
    "\n",
    "Il modello tuning non è stato efficace in nessun caso, ottenendo come valori di accuracy **68%** e di perdira sopra l'**1**. \n",
    "\n",
    "Il modello Voxprofunda continua a eccellere con un'accuratezza di **88%**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca198ba7-ba84-44f9-a9e7-d0c6f0a8acfd",
   "metadata": {},
   "source": [
    "## Dataset + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26512a8c-52f4-40de-a214-f578ad5cd827",
   "metadata": {},
   "source": [
    "### Valutazione spettrogrammi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced87918-34ac-4778-9100-43e21b9f4ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Opt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rumore</th>\n",
       "      <th>Accuratezza</th>\n",
       "      <th>Perdita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voxprofunda</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.710</td>\n",
       "      <td>1.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.680</td>\n",
       "      <td>1.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.662</td>\n",
       "      <td>1.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.657</td>\n",
       "      <td>1.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.653</td>\n",
       "      <td>1.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.599</td>\n",
       "      <td>1.413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modello      Opt      Dataset Rumore  Accuratezza  \\\n",
       "0                 voxprofunda     adam  spectrogram     Sì        0.812   \n",
       "1  tuned_improved_basic_model  rmsprop  spectrogram     Sì        0.710   \n",
       "2        improved_basic_model  rmsprop  spectrogram     Sì        0.703   \n",
       "3  tuned_improved_basic_model     adam  spectrogram     Sì        0.680   \n",
       "4        improved_basic_model     adam  spectrogram     Sì        0.662   \n",
       "5                 basic_model     adam  spectrogram     Sì        0.657   \n",
       "6                 basic_model  rmsprop  spectrogram     Sì        0.653   \n",
       "7              bp_basic_model  rmsprop  spectrogram     Sì        0.644   \n",
       "8              bp_basic_model     adam  spectrogram     Sì        0.599   \n",
       "\n",
       "   Perdita  \n",
       "0    0.693  \n",
       "1    1.296  \n",
       "2    1.058  \n",
       "3    1.356  \n",
       "4    1.152  \n",
       "5    1.283  \n",
       "6    1.219  \n",
       "7    1.514  \n",
       "8    1.413  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spect_rmsprop_noise = create_table(\"spectrogram\", noise=True)\n",
    "df_spect_adam_noise = create_table(\"spectrogram\", optimizer=\"adam\", noise=True)\n",
    "\n",
    "# Aggiunta resnet\n",
    "spect_mixed_test_ds = DatasetConverter(mixed_test_ds)\n",
    "spect_mixed_test_ds = spect_mixed_test_ds.convert(\"spectrogram\")\n",
    "\n",
    "acc, loss = evaluate_onnx_model(\"bestmodels/noise/resnet/voxprofunda_spect.onnx\", spect_mixed_test_ds)\n",
    "new_row = [\"voxprofunda\", \"adam\", \"spectrogram\", \"Sì\", acc, loss]\n",
    "\n",
    "df_spect_adam_noise.loc[-1] = new_row; df_spect_adam_noise.index = df_spect_adam_noise.index + 1\n",
    "# fine aggiunta resnet\n",
    "\n",
    "df_spect_noise = pd.concat([df_spect_rmsprop_noise, df_spect_adam_noise]).sort_values(by=\"Accuratezza\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_spect_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a87cb67-05d0-4fa4-86df-b1d4a4fcca3e",
   "metadata": {},
   "source": [
    "Come era facile intuire, aggiungendo del rumore agli audio originali le prestazioni generali sono peggiorate. I modelli con l'ottimizzatore adam, eccetto Voxprofunda, tendono ad avere accuratezze inferiori e perdite più alte, indicando che potrebbero non essere ottimizzati al meglio per questo specifico compito.\n",
    "\n",
    "Il Tuned Improved Basic Model e l'Improved Basic Model seguono, ma con **10** punti percentuale in meno di accuratezza e presentano perdite significativamente più alte, suggerendo possibili difficoltà di convergenza.  \n",
    "\n",
    "I modelli convolutivi base e bp basic mostrano basse performance, sia per accuratezza che per perdita, suggerendo problemi di sovra-allenamento o difficoltà a gestire il rumore. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb8ea06-2efb-402a-a763-e3f7918d8eb0",
   "metadata": {},
   "source": [
    "### Valutazione filterbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c20549a6-1129-4553-a15a-43cd4b90caa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Opt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rumore</th>\n",
       "      <th>Accuratezza</th>\n",
       "      <th>Perdita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voxprofunda</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.739</td>\n",
       "      <td>1.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.727</td>\n",
       "      <td>1.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.624</td>\n",
       "      <td>1.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>filterbanks</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.594</td>\n",
       "      <td>1.363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modello      Opt      Dataset Rumore  Accuratezza  \\\n",
       "0                 voxprofunda     adam  filterbanks     Sì        0.795   \n",
       "1        improved_basic_model  rmsprop  filterbanks     Sì        0.759   \n",
       "2  tuned_improved_basic_model  rmsprop  filterbanks     Sì        0.739   \n",
       "3        improved_basic_model     adam  filterbanks     Sì        0.727   \n",
       "4  tuned_improved_basic_model     adam  filterbanks     Sì        0.715   \n",
       "5                 basic_model  rmsprop  filterbanks     Sì        0.713   \n",
       "6                 basic_model     adam  filterbanks     Sì        0.665   \n",
       "7              bp_basic_model  rmsprop  filterbanks     Sì        0.624   \n",
       "8              bp_basic_model     adam  filterbanks     Sì        0.594   \n",
       "\n",
       "   Perdita  \n",
       "0    0.756  \n",
       "1    0.952  \n",
       "2    1.056  \n",
       "3    1.036  \n",
       "4    0.963  \n",
       "5    1.244  \n",
       "6    1.327  \n",
       "7    1.535  \n",
       "8    1.363  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fb_rmsprop_noise = create_table(\"filterbanks\", noise=True)\n",
    "df_fb_adam_noise = create_table(\"filterbanks\", optimizer=\"adam\", noise=True)\n",
    "\n",
    "# Aggiunta resnet\n",
    "fb_mixed_test_ds = DatasetConverter(mixed_test_ds)\n",
    "fb_mixed_test_ds = fb_mixed_test_ds.convert(\"filterbanks\")\n",
    "\n",
    "acc, loss = evaluate_onnx_model(\"bestmodels/noise/resnet/voxprofunda_fb.onnx\", fb_mixed_test_ds)\n",
    "new_row = [\"voxprofunda\", \"adam\", \"filterbanks\", \"Sì\", acc, loss]\n",
    "\n",
    "df_fb_adam_noise.loc[-1] = new_row; df_fb_adam_noise.index = df_fb_adam_noise.index + 1\n",
    "# fine aggiunta resnet\n",
    "\n",
    "df_fb_noise = pd.concat([df_fb_rmsprop_noise, df_fb_adam_noise]).sort_values(by=\"Accuratezza\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_fb_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9289d0e5-7914-4fee-a812-e524f5eed941",
   "metadata": {},
   "source": [
    "Nella tabella dei filterbanks, il modello Voxprofunda si distingue con la più alta accuratezza **79.5** e una perdita relativamente bassa. \n",
    "\n",
    "L'Improved Basic Model segue con un'accuratezza di **75.9**, mostrando una performance solida, ma inferiore rispetto al VGGVox. Il Tuned Improved Basic Model con **rmsprop** e l'Improved Basic Model con **adam** presentano accuratezze leggermente inferiori, rispettivamente **73.9** e **72.7**.\n",
    "\n",
    "I modelli Basic e BP Basic mostrano performance variabili, con accuratezze che vanno da 0.713 a 0.594 e perdite che vanno da 1.244 a 1.535, suggerendo una maggiore difficoltà nel gestire il rumore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22a5ad-844c-42a8-89ff-b7e4fb025582",
   "metadata": {},
   "source": [
    "### Valutazione MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76a33152-6070-4a19-b8d7-a720b65757d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Opt</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rumore</th>\n",
       "      <th>Accuratezza</th>\n",
       "      <th>Perdita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voxprofunda</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.632</td>\n",
       "      <td>1.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.621</td>\n",
       "      <td>1.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.612</td>\n",
       "      <td>1.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.594</td>\n",
       "      <td>1.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.581</td>\n",
       "      <td>1.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>adam</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>Sì</td>\n",
       "      <td>0.510</td>\n",
       "      <td>1.678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modello      Opt Dataset Rumore  Accuratezza  Perdita\n",
       "0                 voxprofunda     adam    mfcc     Sì        0.720    0.978\n",
       "1        improved_basic_model  rmsprop    mfcc     Sì        0.632    1.388\n",
       "2              bp_basic_model  rmsprop    mfcc     Sì        0.625    1.342\n",
       "3        improved_basic_model     adam    mfcc     Sì        0.621    1.451\n",
       "4                 basic_model  rmsprop    mfcc     Sì        0.612    1.539\n",
       "5              bp_basic_model     adam    mfcc     Sì        0.594    1.383\n",
       "6  tuned_improved_basic_model  rmsprop    mfcc     Sì        0.581    1.614\n",
       "7  tuned_improved_basic_model     adam    mfcc     Sì        0.573    1.501\n",
       "8                 basic_model     adam    mfcc     Sì        0.510    1.678"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc_rmsprop_noise = create_table(\"mfcc\", noise=True)\n",
    "df_mfcc_adam_noise = create_table(\"mfcc\", optimizer=\"adam\", noise=True)\n",
    "\n",
    "# Aggiunta resnet\n",
    "mfcc_mixed_test_ds = DatasetConverter(mixed_test_ds)\n",
    "mfcc_mixed_test_ds = mfcc_mixed_test_ds.convert(\"mfcc\")\n",
    "\n",
    "acc, loss = evaluate_onnx_model(\"bestmodels/noise/resnet/voxprofunda_mfcc.onnx\", mfcc_mixed_test_ds)\n",
    "new_row = [\"voxprofunda\", \"adam\", \"mfcc\", \"Sì\", acc, loss]\n",
    "\n",
    "df_mfcc_adam_noise.loc[-1] = new_row; df_mfcc_adam_noise.index = df_mfcc_adam_noise.index + 1\n",
    "# fine aggiunta resnet\n",
    "\n",
    "df_mfcc_noise = pd.concat([df_mfcc_rmsprop_noise, df_mfcc_adam_noise]).sort_values(by=\"Accuratezza\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_mfcc_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250601f-c5c4-42bf-9b0f-7dee05705653",
   "metadata": {},
   "source": [
    "Per quanto riguarda i MFCC, il modello Voxprofunda mantiene il primato, ma con dei risultati decisamente inferiori, con un'accuratezza di **72%**.\n",
    "\n",
    "L'Improved Basic Model **rmsprop** segue con un'accuratezza di **63%**.\n",
    "\n",
    "Gli altri modelli, inclusi il Basic Model e il Tuned Improved Basic Model, mostrano performance inferiori, con accuratezze che variano da 0.612 a 0.510. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935be31e-4795-4639-853a-730e1f018030",
   "metadata": {},
   "source": [
    "## Conclusioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e05da5-fd97-4719-9249-82e36a8715fe",
   "metadata": {},
   "source": [
    "Dall'analisi delle tabelle sui vari dataset (spettrogrammi, filterbanks e MFCC) con e senza rumore, emergono alcune considerazioni chiave riguardo le performance dei modelli di riconoscimento vocale:\n",
    "\n",
    "- Voxprofunda, si è dimostrato il più performante in quasi tutti i contesti analizzati, sia in presenza che in assenza di rumore. La sua capacità di mantenere alta accuratezza e bassa perdita in condizioni diverse indica una robustezza superiore e una buona generalizzazione.\n",
    "\n",
    "- L'aggiunta di rumore tende a peggiorare le performance di tutti i modelli, come ci si aspetterebbe. Tuttavia, Voxprofunda riesce a mantenere una superiorità relativa, suggerendo che sia meglio equipaggiato per gestire dataset rumorosi rispetto agli altri modelli.\n",
    "\n",
    "- I modelli che utilizzano l'ottimizzatore adam generalmente mostrano performance leggermente inferiori rispetto agli equivalenti con rmsprop. Questo è evidente sia nei dataset con rumore che senza rumore.\n",
    "\n",
    "- I modelli migliorati con i blocchi residui hanno mostrato performance migliori soprattuto per quanto riguarda il dataset senza rumore e sembrano lavorare meglio con l'ottimizzatore adam.\n",
    "\n",
    "- I modelli migliorati con lo strato di dropout hanno portato benefici soprattuto quando si tratta il dataset senza rumore e in combinazione all'ottimizzatore rmsprop\n",
    "\n",
    "- I modelli mostrano variazioni di performance a seconda della rappresentazione utilizzata (spettrogrammi, filterbanks, MFCC). In generale, le performance sono più alte nei dataset senza rumore, con differenze minori tra le rappresentazioni quando il rumore è presente.\n",
    "\n",
    "- Ulteriori miglioramenti potrebbero essere ottenuti esplorando nuove architetture o ulteriori tecniche di pre-elaborazione e ottimizzazione."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
