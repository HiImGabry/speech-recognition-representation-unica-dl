{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a85d31-66c4-4bb2-8071-598b30325f89",
   "metadata": {},
   "source": [
    "# Analisi degli Spettrogrammi di Immagini Audio\n",
    "\n",
    "In questo notebook, eseguiremo un'analisi sugli spettrogrammi di alcune immagini audio. Il nostro obiettivo è estrarre informazioni utili dagli spettrogrammi e rappresentarle graficamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8fa641-8f78-4dda-a48d-f7cbc9d7b4ba",
   "metadata": {},
   "source": [
    "## Importazione delle Librerie Necessarie\n",
    "\n",
    "Per prima cosa, importiamo tutte le librerie necessarie per l'analisi e la visualizzazione dei dati.\n",
    "Oltre quelle già viste durante il corso, andiamo a utilizzare scipy per estrarre le informazioni dagli audio, e os per muoverci all'interno delle directory del computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cf49ca-81d5-4827-8014-31c09a51ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importiamo una serie di liberie che ci serviranno durante la nostra analisi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b726e-a6bd-45df-bf86-2da404c45ae5",
   "metadata": {},
   "source": [
    "## Funzioni Utilizzate \n",
    "\n",
    "Andiamo a creare delle funzioni che ci serviranno durante la nostra analisi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5b8e5-aecb-45ea-89b2-13f4fc6ad637",
   "metadata": {},
   "source": [
    "La prima funzione è wav_to_spectr, che si occupa di trasformare i file audio, i quali hanno un formato .wav, in spettrogrammi. \n",
    "Per farlo passiamo alla funzione il nome della classe che da cui vogliamo estrarre l'immagine. Andiamo a utilizzare delle funzioni di scipy che, come precedentemente detto, ci permettono di estrarre le informazioni che ci servono ovvero un array di frequenze espresse in Hz, un array con la durata in secondi e lo spettrogramma. Infine restituisce questi valori, da quale file audio sono stati estratti e in quale cartella era presente quel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9842a36d-1206-4160-b104-6df34b609c5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def wav_to_spectr(arg1):\n",
    "    dir = \"./tensorflow-speech-recognition-challenge/train/audio/\" # creiamo una variabile con il percorso del nostro dataset\n",
    "    os.chdir(dir)\n",
    "    dir_audio = arg1  \n",
    "    os.chdir(dir_audio) # entriamo in quella directory \n",
    "    audio = random.choice(os.listdir()) # scegliamo in modo randomico un audio all'interno della nostra cartella\n",
    "    sample_rate, samples = wavfile.read(audio) # legge il file audio\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate) # creare lo spettrogramma\n",
    "    os.chdir(\"../../../../\") # torniamo alla libreria dove è situato il nostro file jupyter\n",
    "    return frequencies, times, spectrogram, audio, dir_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95365884-1c38-44f1-b387-74a1524d486f",
   "metadata": {},
   "source": [
    "La seconda funzione racchiude tutti i comandi utili per la visualizzazione dei dati. Quando chiamata utilizza la funzione vista prima per estrarre le informazioni di quattro audio diversi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59cfdea1-3cab-4373-be45-ee28d3305561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrograms():\n",
    "    # usiamo la funzione definita prima per andare a creare 4 spettrogrammi, 2 per label cosi da analizzare le differenze\n",
    "    frequencies_right1, times_right1, spectrogram_right1, audio_right1, dir_audio_right1 = wav_to_spectr('right') \n",
    "    frequencies_right2, times_right2, spectrogram_right2, audio_right2, dir_audio_right2 = wav_to_spectr('right')\n",
    "    frequencies_tree1, times_tree1, spectrogram_tree1, audio_tree1, dir_audio_tree1 = wav_to_spectr('tree')\n",
    "    frequencies_tree2, times_tree2, spectrogram_tree2, audio_tree2, dir_audio_tree2 = wav_to_spectr('tree')\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 8))  # aumenta la dimensione della figura\n",
    "    fig.tight_layout(pad=3.0)  # aggiungi padding tra i subplot\n",
    "    \n",
    "    # Primo spettrogramma\n",
    "    ax[0, 0].pcolormesh(times_right1, frequencies_right1, np.log(spectrogram_right1))\n",
    "    ax[0, 0].set_ylabel('Frequency [Hz]') \n",
    "    ax[0, 0].set_xlabel('Time [sec]')\n",
    "    ax[0, 0].set_title(audio_right2 + \" dentro: \" + dir_audio_right2)\n",
    "    \n",
    "    # Secondo spettrogramma\n",
    "    ax[0, 1].pcolormesh(times_right2, frequencies_right2, np.log(spectrogram_right2))\n",
    "    ax[0, 1].set_ylabel('Frequency [Hz]') \n",
    "    ax[0, 1].set_xlabel('Time [sec]')\n",
    "    ax[0, 1].set_title(audio_right2 + \" dentro: \" + dir_audio_right2)\n",
    "    \n",
    "    # Terzo spettrogramma\n",
    "    ax[1, 0].pcolormesh(times_tree1, frequencies_tree1, np.log(spectrogram_tree1))\n",
    "    ax[1, 0].set_ylabel('Frequency [Hz]') \n",
    "    ax[1, 0].set_xlabel('Time [sec]')\n",
    "    ax[1, 0].set_title(audio_tree2 + \" dentro: \" + dir_audio_tree2)\n",
    "    \n",
    "    # Quarto spettrogramma\n",
    "    ax[1, 1].pcolormesh(times_tree2, frequencies_tree2, np.log(spectrogram_tree2))\n",
    "    ax[1, 1].set_ylabel('Frequency [Hz]') \n",
    "    ax[1, 1].set_xlabel('Time [sec]')\n",
    "    ax[1, 1].set_title(audio_tree2 + \" dentro: \" + dir_audio_tree2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde2357-2e19-4618-a010-9b6289766748",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrograms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07c1bd-4140-49dd-b0b0-80faa8f59219",
   "metadata": {},
   "source": [
    "Mostriamo gli spettrogrammi di due label diverse. Possiamo notare, anche a occhio, come gli audio con la stessa label abbiano frequenze simili "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
