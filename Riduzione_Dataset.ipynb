{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaJE0Su5tMoq"
   },
   "source": [
    "# Riduzione del dataset\n",
    "\n",
    "In questo notebook eseguiremo la riduzione del dataset. L'obiettivo è quello di diminuire la quantità di audio per label, mantenendo le caratteristiche di sbilanciamento generali del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installazione e importazione delle librerie necessarie\n",
    "\n",
    "Installiamo e importiamo le librerie che ci torneranno utili per la riduzione del dataset. In questo caso Tensorflow sarà utilizzato per estrarre il dataset dalla directory, mentre le restanti saranno utilizate la manipolazione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installiamo la libreria di tensorflow\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrazione dataset\n",
    "La funzione `audio_dataset_from_directory(directory)` è un modo semplice e veloce per ottenere informazioni dalle **sottodirectory di un dataset**. Il funzionamento di base è uguale ad altre funzioni viste durante il corso, come per esempio `image_dataset_from_directory`. Nel nostro caso il dataset è composto da **30 sottodirectory**, corrispondenti a **30 classi** rappresentate come **indici numerici**, e con una **batch_size di 32**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64721 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "# estraiamo il nostro dataset originale\n",
    "train_ds = tf.keras.utils.audio_dataset_from_directory(directory='../original/train/audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero classi: 30\n",
      "Classi: ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "# stampiamo il numero delle classi e i nomi delle classi del dataset\n",
    "print('Numero classi:', len(train_ds.class_names))\n",
    "print('Classi:',train_ds.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzioni utilizzate\n",
    "Andiamo a creare le funzioni che ci serviranno per la riduzione del dataset.\n",
    "\n",
    "La prima funzione è `copy_files`, che si occupa di creare la directory di destinazione (quindi quella del dataset ridotto) e di copiare i file scelti. La seconda funzione `downsample_class` riduce il dataset, mantenendo in questo caso un quantitativo di audio proporzionato alla quantità iniziale.\n",
    "\n",
    "L'idea iniziale era quella di campionare 300 audio per ogni label, ma abbiamo deciso di utilizzare una percentuale piuttosto che un numero costante, cosi da  poter mantenere lo sbilanciamento del dataset originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per copiare i file\n",
    "def copy_files(files, src_dir, dest_dir):\n",
    "    if not os.path.exists(dest_dir): # se la directory di destinazione non esiste allora la creo\n",
    "        os.makedirs(dest_dir)\n",
    "    for file in files: # copio ogni file che mi viene passato nella directory di destinazione, quindi nella directory della classe\n",
    "        shutil.copy(os.path.join(src_dir, file), os.path.join(dest_dir, file))\n",
    "\n",
    "# funzione per diminuire la quantità di audio per label\n",
    "def downsample_class(class_dir, class_name, target_dir, ratio):\n",
    "    files = os.listdir(class_dir) # mi salvo tutti i file della classe in una variabile\n",
    "    num_files_to_keep = int(len(files) * ratio) # calcolo la quantità di file che devo mantenere per la classe in questione\n",
    "    files_to_keep = random.sample(files, num_files_to_keep) # scelgo randomicamente i file da mantenere\n",
    "    \n",
    "    # chiamo la funzione precedentemente dichiarata per copiare i file nella directory\n",
    "    copy_files(files_to_keep, class_dir, os.path.join(target_dir, class_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quindi utilizziamo le funzioni appena dichiarate per ridurre il dataset dell'80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = '../original/train/audio' # path dataset originale\n",
    "downsampled_dir = '../reduced_dataset/train/audio' # path dataset ridotto\n",
    "\n",
    "classes = [dir for dir in os.listdir(original_dir) if os.path.isdir(os.path.join(original_dir, dir))]\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(original_dir, class_name)\n",
    "    downsample_class(class_dir, class_name, downsampled_dir, 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con queste righe di codice abbiamo terminato la riduzione del training set, passando da una **dimensione iniziale di 1.90 GB con 64721 audio totali** a una **dimensione finale di 389 MB con 12933 audio totali**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMnkQpgQIjQSCq/KWijIiaA",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
