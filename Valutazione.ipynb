{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "751b9f51-b2f9-4758-be26-88a70f1e6d04",
   "metadata": {},
   "source": [
    "# Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52578c8a-1c8c-45fb-a305-0d85a20ad359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import scipy.fftpack as scipy\n",
    "import onnxruntime as rt\n",
    "import tf2onnx\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b8aee5-bb5d-498f-a194-3991a98d6758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12933 files belonging to 30 classes.\n",
      "Using 7760 files for training.\n",
      "Using 5173 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, validation_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory='../reduced_dataset/dataset/audio',\n",
    "    validation_split=0.4, # stiamo mettendo da parte il 40% del dataset, che sarà suddiviso in validation set e test set\n",
    "    shuffle=True,\n",
    "    subset='both', # necessario se stiamo utilizzando validation_split (se no darebbe errore)\n",
    "    seed=0 # necessario se stiamo utilizzando sia shuffle che validation_split (se no darebbe errore)\n",
    ")\n",
    "\n",
    "val_ds = validation_ds.take(validation_ds.cardinality() // 2) # ho cambiato nome del validation_ds in modo tale da non creare problemi con l'istruzione seguente\n",
    "test_ds = validation_ds.skip(validation_ds.cardinality() // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474c96ec-5ad3-4b9b-8acb-fd9c7364f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConverter:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def convert(self, option):\n",
    "        available_options = ['spectrogram', 'filterbanks', 'mfcc']\n",
    "        \n",
    "        if option == available_options[0]:\n",
    "            return self.get_spectrogram_dataset()\n",
    "        elif option == available_options[1]:\n",
    "            return self.get_filterbanks_dataset()\n",
    "        elif option == available_options[2]:\n",
    "            return self.get_mfcc_dataset()\n",
    "        else:\n",
    "            raise ValueError(f\"Opzione non disponibile: inserire una delle seguenti opzioni: {available_options}\")\n",
    "    \n",
    "    # INIZIO SPETTROGRAMMI\n",
    "    def squeeze(self, audio, labels):\n",
    "        audio = tf.squeeze(audio, axis=-1)\n",
    "        return audio, labels\n",
    "    \n",
    "    def get_spectrogram(self, waveform):\n",
    "    # applichiamo la short-time Fourier transorm\n",
    "        spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
    "        spectrogram = tf.abs(spectrogram)\n",
    "        \n",
    "        return spectrogram[..., tf.newaxis]\n",
    "    \n",
    "    def get_spectrogram_dataset(self):\n",
    "        # squeeze\n",
    "        self.dataset = self.dataset.map(self.squeeze, tf.data.AUTOTUNE)\n",
    "        self.dataset = self.dataset.map(lambda x, y: (self.get_spectrogram(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        \n",
    "        return self.dataset\n",
    "\n",
    "    # FINE SPETTROGRAMMI\n",
    "\n",
    "    def convert_to_numpy(self, dataset):\n",
    "        audio_data = []\n",
    "        labels = []\n",
    "    \n",
    "        dataset = dataset.unbatch()\n",
    "        \n",
    "        for audio, label in dataset:\n",
    "            audio_data.append(audio.numpy())  # Assuming audio is a tensor, convert to numpy array\n",
    "            labels.append(label.numpy())      # Assuming label is a tensor, convert to numpy array\n",
    "        \n",
    "        audio_data = np.array(audio_data)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        return audio_data, labels\n",
    "    \n",
    "    # INIZIO FILTERBANKS\n",
    "    def makeHamming(self, M):\n",
    "        R = (( M - 1 ) / 2 , M / 2)[M % 2 == 0]\n",
    "        w = (np.hamming(M), np.hamming(M + 1))[M % 2 == 0]\n",
    "        if M % 2 != 0:\n",
    "            w[0] = w[0]/2\n",
    "            w[M-1] = w[M-1]/2\n",
    "        else:\n",
    "            w = w[:M]\n",
    "    \n",
    "        return w\n",
    "\n",
    "    def hztomel(self, hz):\n",
    "        return (2595 * np.log10(1 + hz / 700))\n",
    "\n",
    "    def meltohz(self, mel):\n",
    "        return (700 * (10**(mel / 2595) - 1))\n",
    "\n",
    "    def compute_filterbanks(self, audios_np, pre_emphasis=0.97, sample_rate=16000, frame_size=0.025, frame_stride=0.01, NFFT=512, nfilt=40):\n",
    "        filterbanks_np = []\n",
    "        \n",
    "        for samples in audios_np:\n",
    "            emphasized_audio = np.append(samples[0], samples[1:] - pre_emphasis * samples[:-1])\n",
    "            audio_length = len(emphasized_audio)\n",
    "    \n",
    "            frame_length, frame_step = int(frame_size * sample_rate), int(frame_stride * sample_rate)\n",
    "    \n",
    "            num_frames = int(np.ceil(float(np.abs(audio_length - frame_length)) / frame_step))\n",
    "    \n",
    "            pad_audio_length = num_frames * frame_step + frame_length\n",
    "            z = np.zeros((pad_audio_length - audio_length))\n",
    "            pad_audio = np.append(emphasized_audio, z)\n",
    "    \n",
    "            indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "            frames = pad_audio[indices.astype(np.int32, copy=False)]\n",
    "    \n",
    "            # Usiamo la funzione di Hamming\n",
    "            hamming_window = self.makeHamming(frame_length)\n",
    "    \n",
    "            mag_frames = np.absolute(np.fft.rfft(frames, NFFT))  # Magnitudo della FFT\n",
    "            pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))\n",
    "    \n",
    "            # convertiamo hz in mel\n",
    "            low_freq_mel = self.hztomel(0)\n",
    "            high_freq_mel = self.hztomel(sample_rate / 2)\n",
    "    \n",
    "            mel_points = np.linspace(low_freq_mel, high_freq_mel, nfilt + 2)\n",
    "            hz_points = self.meltohz(mel_points) \n",
    "    \n",
    "            bin = np.floor((NFFT + 1) * hz_points / sample_rate)\n",
    "    \n",
    "            fbank = np.zeros((nfilt, int(np.floor(NFFT / 2 + 1))))\n",
    "    \n",
    "            for m in range(1, nfilt + 1):\n",
    "                f_m_minus = int(bin[m - 1])\n",
    "                f_m = int(bin[m])\n",
    "                f_m_plus = int(bin[m + 1])\n",
    "    \n",
    "                for k in range(f_m_minus, f_m):\n",
    "                    fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "                for k in range(f_m, f_m_plus):\n",
    "                    fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "    \n",
    "            # in questo momento invece calcoliamo i filter banks per i segmenti di audio, utilizzando i filtri triangolari appena creati\n",
    "            filter_banks = np.dot(pow_frames, fbank.T)\n",
    "            filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks)\n",
    "            filter_banks = 20 * np.log10(filter_banks)\n",
    "    \n",
    "            filterbanks_np.append(filter_banks)\n",
    "        \n",
    "        return np.array(filterbanks_np)\n",
    "    \n",
    "    def get_filterbanks_dataset(self): \n",
    "        audios, labels = self.convert_to_numpy(self.dataset)\n",
    "\n",
    "        filterbanks = self.compute_filterbanks(audios)\n",
    "        filterbanks = np.expand_dims(filterbanks, axis=-1)\n",
    "\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((filterbanks, labels))\n",
    "        self.dataset = self.dataset.batch(32)\n",
    "        \n",
    "        return self.dataset\n",
    "    # FINE FILTERBANKS\n",
    "\n",
    "    # INIZIO MFCC\n",
    "    def compute_mfcc(self, filter_banks, num_ceps=12, cep_lifter=22):\n",
    "        mfcc_np = []\n",
    "        \n",
    "        for f in filter_banks:\n",
    "            mfcc = scipy.dct(f, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)]\n",
    "\n",
    "            (nframes, ncoeff) = mfcc.shape\n",
    "            n = np.arange(ncoeff)\n",
    "            \n",
    "            lift = 1 + (cep_lifter / 2) * np.sin(np.pi * n / cep_lifter)\n",
    "            mfcc *= lift\n",
    "\n",
    "            mfcc_np.append(mfcc)\n",
    "        \n",
    "        return np.array(mfcc_np)\n",
    "    \n",
    "    \n",
    "    def get_mfcc_dataset(self):\n",
    "        audios, labels = self.convert_to_numpy(self.dataset)\n",
    "\n",
    "        filterbanks = self.compute_filterbanks(audios)\n",
    "        mfcc = self.compute_mfcc(filterbanks)\n",
    "        \n",
    "        mfcc = np.expand_dims(mfcc, axis=-1)\n",
    "        \n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((mfcc, labels))\n",
    "        self.dataset = self.dataset.batch(32)\n",
    "        \n",
    "        return self.dataset\n",
    "    \n",
    "    # FINE MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46883168-0326-45c5-a6c9-f2f7f8018707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_onnx_model(path_model_onnx, test_ds):\n",
    "    # il fatto che sia suddiviso in batch mi crea problemi, perciò lo risolvo togliendoli\n",
    "    test_ds = test_ds.unbatch()\n",
    "    \n",
    "    # carico il modello utilizzando il file onnx\n",
    "    m = rt.InferenceSession(path_model_onnx)\n",
    "    \n",
    "    # trasformo il dataset in array numpy\n",
    "    spectrogram_np = np.array([spectrogram.numpy() for spectrogram, _ in test_ds], dtype=np.float32)\n",
    "    labels_np = np.array([label.numpy() for _, label in test_ds])\n",
    "    \n",
    "    # eseguo le predizione del modello\n",
    "    pred_onnx = m.run(None, {'input': spectrogram_np})\n",
    "    # ottengo la predizione corretta\n",
    "    predictions = np.argmax(pred_onnx[0], axis=1)\n",
    "    # computo la accuratezza\n",
    "    accuracy = np.mean(predictions == labels_np)\n",
    "    # stampo l'accuratezza\n",
    "    return f\"{accuracy:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06cebbe-20c1-4a68-aa9b-bbf2dfedd9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creiamo le colonne e il dataframe\n",
    "headers = [\"Modello\", \"Dataset\", \"Rumore\", \"Accuratezza\"]\n",
    "\n",
    "def create_table(dataset_name, optimizer=\"rmsprop\", noise=False):\n",
    "    dataset = DatasetConverter(test_ds)\n",
    "    dataset = dataset.convert(dataset_name)\n",
    "    \n",
    "    path = f\"bestmodels/noise/{optimizer}/\" if noise else f\"bestmodels/{optimizer}/\"\n",
    "    path += dataset_name + \"/\"\n",
    "\n",
    "    df = pd.DataFrame(columns=headers)\n",
    "\n",
    "    for model in os.listdir(path):\n",
    "        if model.endswith(\"onnx\"):\n",
    "            new_row = []\n",
    "            new_row.append(model.split(\".onnx\")[0])\n",
    "            new_row.append(path.split(\"/\")[-2])\n",
    "            \n",
    "            if noise:\n",
    "                new_row.append(\"Sì\")\n",
    "            else:\n",
    "                new_row.append(\"No\")\n",
    "            \n",
    "            new_row.append(evaluate_onnx_model(path+model, dataset))\n",
    "\n",
    "            df.loc[-1] = new_row\n",
    "            df.index = df.index + 1\n",
    "\n",
    "    return df.sort_values(by=\"Accuratezza\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "358b2122-a320-4817-87e3-5db55de0548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb = create_table(\"filterbanks\")\n",
    "df_spect = create_table(\"spectrogram\")\n",
    "df_mfcc = create_table(\"mfcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033aab1f-899b-4e4e-8eb7-c5a1a1b80e21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_fb \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_table\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilterbanks\u001b[39m\u001b[38;5;124m\"\u001b[39m, noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_table' is not defined"
     ]
    }
   ],
   "source": [
    "df_fb = create_table(\"filterbanks\", noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ed97a7-141d-4108-b572-973e70d7381e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rumore</th>\n",
       "      <th>Accuratezza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bp_basic_model</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>improved_basic_model</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic_model</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tuned_improved_basic_model</td>\n",
       "      <td>spectrogram</td>\n",
       "      <td>No</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Modello      Dataset Rumore Accuratezza\n",
       "2              bp_basic_model  spectrogram     No       0.891\n",
       "1        improved_basic_model  spectrogram     No       0.863\n",
       "3                 basic_model  spectrogram     No       0.828\n",
       "0  tuned_improved_basic_model  spectrogram     No       0.775"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fbb24d8-5c31-4cde-bd7c-726e8fc81a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modello</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Rumore</th>\n",
       "      <th>Accuratezza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>improved_basic_model_mfcc</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basic_model_mfcc</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bp_basic_model_mfcc</td>\n",
       "      <td>mfcc</td>\n",
       "      <td>No</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Modello Dataset Rumore Accuratezza\n",
       "0  improved_basic_model_mfcc    mfcc     No       0.814\n",
       "2           basic_model_mfcc    mfcc     No       0.797\n",
       "1        bp_basic_model_mfcc    mfcc     No       0.796"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d2952-de91-462e-b473-cdcbff63745b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
